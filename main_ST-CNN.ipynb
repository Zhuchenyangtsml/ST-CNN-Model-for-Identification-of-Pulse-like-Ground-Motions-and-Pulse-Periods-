{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043128a-422b-473a-a1ae-dab043bf6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ST-CNN Model for Identification of Pulse-like Ground Motions and Pulse Periods \n",
    "# Chenyang Zhu\n",
    "# For the convenience of batch processing, the code here has been modified on the original basis\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from stockwell import st\n",
    "from scipy.signal import chirp\n",
    "from scipy.interpolate import interp2d\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    dt,  npts= map(float, lines[0].split())\n",
    "    at = np.array([float(line) for line in lines[1:]]) * 9.81\n",
    "    assert len(at) == npts, \"Data point mismatch\"\n",
    "    vt = np.cumsum(np.array(at) * dt)\n",
    "    vt_cm = vt*100\n",
    "    time = np.arange(0, npts * dt, dt)    \n",
    "    return dt, npts, time, vt_cm\n",
    "\n",
    "# Fault-normal ground motion at the Pacoima Dam (upper left abutment) seismic station during the 1971 San Fernando earthquake\n",
    "file_example = \"example.acc\" \n",
    "\n",
    "# Generate velocity time series matrix\n",
    "dt, npts, time, vt_cm = process_file(file_example)\n",
    "T = []\n",
    "T_ans = dt*(npts-1)\n",
    "T.append(T_ans)\n",
    "T = np.array(T).astype(np.float32)\n",
    "\n",
    "# S-Transfrom\n",
    "df = 1./(time[-1]-time[0])\n",
    "fmin = 0  \n",
    "fmax = 10  \n",
    "fmin_samples = int(fmin/df)\n",
    "fmax_samples = int(fmax/df)                        \n",
    "stock = np.abs(st.st(vt_cm, fmin_samples, fmax_samples))\n",
    "frequency = np.linspace(fmin, fmax, stock.shape[0])  \n",
    "f = interp2d(time, frequency.flatten(), stock)\n",
    "\n",
    "# Interpolation\n",
    "new_time_100100 = np.linspace(time[0], time[-1], 100)\n",
    "new_frequency_100100 = np.linspace(frequency.min(), frequency.max(), 100)\n",
    "new_stock_100100 = f(new_time_100100, new_frequency_100100).reshape((100, 100))  \n",
    "new_stock_100100_normalized = new_stock_100100.reshape((-1, 100, 100, 1))\n",
    "\n",
    "new_time_200200 = np.linspace(time[0], time[-1], 200)\n",
    "new_frequency_200200 = np.linspace(frequency.min(), frequency.max(), 200)\n",
    "new_stock_200200 = f(new_time_200200, new_frequency_200200).reshape((200, 200)) \n",
    "new_stock_200200_normalized = new_stock_200200.reshape((-1, 200, 200, 1))\n",
    "\n",
    "new_time_300300 = np.linspace(time[0], time[-1], 300)\n",
    "new_frequency_300300 = np.linspace(frequency.min(), frequency.max(), 300)\n",
    "new_stock_300300 = f(new_time_300300, new_frequency_300300).reshape((300, 300)) \n",
    "new_stock_300300_normalized = new_stock_300300.reshape((-1, 300, 300, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d11df-9ff2-486c-aa04-281f885499fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strict Model\n",
    "\n",
    "class Strict_ConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Strict_ConvNet, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(200, 200, 1)) \n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))  \n",
    "        self.conv2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)) \n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.flatten = tf.keras.layers.Flatten() \n",
    "        self.fc1 = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))  \n",
    "        self.drop1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.fc2 = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)) \n",
    "        self.drop2 = tf.keras.layers.Dropout(0.5)\n",
    "        self.fc3 = tf.keras.layers.Dense(3, activation='softmax') \n",
    "    def call(self, inputs):\n",
    "        s, t = inputs\n",
    "        x = self.conv1(s)\n",
    "        x = self.pool1(x) \n",
    "        x = self.conv2(x) \n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x) \n",
    "        x = self.fc1(x)  \n",
    "        x = tf.concat([x, t], axis=1) \n",
    "        x = self.drop1(x)      \n",
    "        x = self.fc2(x)  \n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "Strict_model = Strict_ConvNet()\n",
    "\n",
    "Strict_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "Strict_model((np.zeros((1, 200, 200, 1)), np.zeros((1, 1))))\n",
    "\n",
    "Strict_model.load_weights('200_200 strict 2 128.h5')\n",
    "\n",
    "Strict_predictions = Strict_model.predict((new_stock_200200_normalized, tf.expand_dims(T, axis=1)))\n",
    "\n",
    "Strict_predictions = np.array(Strict_predictions)\n",
    "\n",
    "Strict_predicted_labels = np.argmax(Strict_predictions, axis=1)-1\n",
    "\n",
    "# [1] == pulse-like; [0] == ambiguous; [-1] == non-pulse-like\n",
    "print(\"Strict Identification: \", Strict_predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aafefb-7c66-4198-8334-c72a533f0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Model\n",
    "\n",
    "class General_ConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(General_ConvNet, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(100, 100, 1)) \n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))  \n",
    "        self.conv2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)) \n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)) \n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)) \n",
    "        self.pool4 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.flatten = tf.keras.layers.Flatten() \n",
    "        self.fc1 = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))  \n",
    "        self.drop1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.fc2 = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)) \n",
    "        self.drop2 = tf.keras.layers.Dropout(0.5)\n",
    "        self.fc3 = tf.keras.layers.Dense(2, activation='softmax') \n",
    "    def call(self, inputs):\n",
    "        s, t = inputs\n",
    "        x = self.conv1(s)\n",
    "        x = self.pool1(x) \n",
    "        x = self.conv2(x) \n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x) \n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x) \n",
    "        x = self.pool4(x)\n",
    "        x = self.flatten(x) \n",
    "        x = self.fc1(x)  \n",
    "        x = tf.concat([x, t], axis=1) \n",
    "        x = self.drop1(x)      \n",
    "        x = self.fc2(x)  \n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "General_model = General_ConvNet()\n",
    "\n",
    "General_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "General_model((np.zeros((1, 100, 100, 1)), np.zeros((1, 1))))\n",
    "\n",
    "General_model.load_weights('100_100 general 4 128.h5')\n",
    "\n",
    "General_predictions = General_model.predict((new_stock_100100_normalized, tf.expand_dims(T, axis=1)))\n",
    "\n",
    "General_predictions = np.array(General_predictions)\n",
    "\n",
    "General_predicted_labels = np.argmax(General_predictions, axis=1)\n",
    "\n",
    "# [1] == pulse-like; [0] == non-pulse-like\n",
    "print(\"General Identification: \", General_predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab5508-0fbd-435c-b219-4fb132e700fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tp Model\n",
    "\n",
    "class Tp_ConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Tp_ConvNet, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(300, 300, 1)) \n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))  \n",
    "        self.conv2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu') \n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu') \n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.conv4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu') \n",
    "        self.pool4 = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.flatten = tf.keras.layers.Flatten() \n",
    "        self.fc1 = tf.keras.layers.Dense(128, activation='relu')  \n",
    "        self.drop1 = tf.keras.layers.Dropout(0.01)\n",
    "        self.fc2 = tf.keras.layers.Dense(128, activation='relu') \n",
    "        self.drop2 = tf.keras.layers.Dropout(0.01)\n",
    "        self.fc3 = tf.keras.layers.Dense(1) \n",
    "    def call(self, inputs):\n",
    "        s, t = inputs\n",
    "        x = self.conv1(s) \n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x) \n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.flatten(x)  \n",
    "        x = self.fc1(x)  \n",
    "        x = tf.concat([x, t], axis=1)      \n",
    "        x = self.drop1(x)       \n",
    "        x = self.fc2(x)  \n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "Tp_model = Tp_ConvNet()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "Tp_model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "Tp_model((np.zeros((1, 300, 300, 1)), np.zeros((1, 1))))\n",
    "\n",
    "Tp_model.load_weights('300_300 Tp 4 128.h5')\n",
    "\n",
    "Tp_predictions = Tp_model.predict((new_stock_300300_normalized, tf.expand_dims(T, axis=1)))\n",
    "\n",
    "Tp_predictions = np.array(Tp_predictions)\n",
    "\n",
    "print(\"Tp Identification: \", Tp_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145a9e2-f4bc-49ac-bbb6-ba0cdbe27d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
